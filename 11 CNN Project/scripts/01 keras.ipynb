{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.utils import Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Activation\n",
    "from keras import datasets, layers, models\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoduleDatasetGenerator(Sequence):\n",
    "    def __init__(self, data_path, image_path, batch_size, image_size, shuffle = True, augment = True):\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.data_path = data_path\n",
    "        self.images_dir = os.path.join(data_path, 'images', image_path)\n",
    "        \n",
    "        if image_path == 'train':\n",
    "            self.labels_file = os.path.join(data_path, 'labels', 'trainlabels.txt')\n",
    "        elif image_path == 'val':\n",
    "            self.labels_file = os.path.join(data_path, 'labels', 'vallabels.txt')\n",
    "        elif image_path == 'test':\n",
    "            self.labels_file = os.path.join(data_path, 'labels', 'testlabels.txt')\n",
    "            \n",
    "        self.dataset = self._load_data(self.images_dir, self.labels_file)\n",
    "        self.indexes = np.arange(len(self.dataset))\n",
    "        self.on_epoch_end()\n",
    "        if self.augment:\n",
    "            self.datagen = ImageDataGenerator(\n",
    "                rotation_range = 30,\n",
    "                width_shift_range = 0.1,\n",
    "                height_shift_range = 0.1,\n",
    "                shear_range = 0.1,\n",
    "                zoom_range = 0.1,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest')\n",
    "        else:\n",
    "            self.datagen = ImageDataGenerator(\n",
    "                shear_range = 0.1,\n",
    "                zoom_range = 0.1,\n",
    "                horizontal_flip = True,\n",
    "                fill_mode = 'nearest')\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_data = [self.dataset[i] for i in batch_indexes]\n",
    "        X, y = self._data_generation(batch_data)\n",
    "        return X, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataset) / self.batch_size))\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def _load_data(self, images_dir, labels_file):\n",
    "        with open(labels_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "\n",
    "        data = []\n",
    "        for line in lines[1:]:\n",
    "            filename, label = line.strip().split()\n",
    "            filename = os.path.basename(filename)\n",
    "            label = int(label)\n",
    "            data.append((filename, label))\n",
    "        return data\n",
    "        \n",
    "    def _data_generation(self, batch_data):\n",
    "        X = np.empty((self.batch_size, *self.image_size, 3))\n",
    "        y = np.empty((self.batch_size), dtype=int)\n",
    "        \n",
    "        for i, (filename, label) in enumerate(batch_data):\n",
    "            img_path = os.path.join(self.images_dir, filename)\n",
    "            img = load_img(img_path, target_size=self.image_size)\n",
    "            img = img_to_array(img)\n",
    "            \n",
    "            if self.augment:\n",
    "                img = self.datagen.random_transform(img)\n",
    "                \n",
    "            X[i] = img\n",
    "            y[i] = label\n",
    "            \n",
    "        return X, y\n",
    "\n",
    "\n",
    "data_path = 'D:/nodule/data'\n",
    "train_gen = NoduleDatasetGenerator(data_path, 'train', batch_size = 32, image_size = (224, 224), shuffle = True, augment = True)\n",
    "valid_gen = NoduleDatasetGenerator(data_path, 'val',   batch_size = 32, image_size = (224, 224), shuffle = True, augment = True)\n",
    "tests_gen = NoduleDatasetGenerator(data_path, 'test',  batch_size = 32, image_size = (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = Conv2D(32, 3, padding='same', activation='relu')\n",
    "        self.conv2 = Conv2D(64, 3, padding='same', activation='relu')\n",
    "        self.maxpool1 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.maxpool2 = MaxPooling2D(pool_size=(2, 2))\n",
    "        self.flatten = Flatten()\n",
    "        self.fc1 = Dense(256, activation = 'relu')\n",
    "        self.dropout1 = Dropout(0.5)\n",
    "        self.fc2 = Dense(32, activation = 'relu')\n",
    "        self.dropout2 = Dropout(0.5)\n",
    "        self.fc3 = Dense(2)\n",
    "\n",
    "        self.batchnorm1 = BatchNormalization()\n",
    "        self.batchnorm2 = BatchNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = LeNet()\n",
    "model.compile(optimizer = 'adam',\n",
    "              loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    epochs = 50,\n",
    "                    validation_data = valid_gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
