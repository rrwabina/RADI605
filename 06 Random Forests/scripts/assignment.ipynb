{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **RADI605: Modern Machine Learning**\n",
    "\n",
    "### Assignment: Random Forests\n",
    "**Romen Samuel Rodis Wabina** <br>\n",
    "Student, PhD Data Science in Healthcare and Clinical Informatics <br>\n",
    "Clinical Epidemiology and Biostatistics, Faculty of Medicine (Ramathibodi Hospital) <br>\n",
    "Mahidol University\n",
    "\n",
    "Note: In case of Python Markdown errors, you may access the assignment through this GitHub [Link](https://github.com/rrwabina/RADI605/blob/main/05%20Adaptive%20Boosting/scripts/assignment.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from numpy import mean\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from mlxtend.plotting import plot_learning_curves\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_binary(df, columns = ['Risk1Yr']):\n",
    "    for column in columns:\n",
    "        df[column] = df[column].apply(lambda x: 0 if x == 'F' else 1)\n",
    "    return df\n",
    "\n",
    "def load_thoracic(path = '../data/ThoraricSurgery.csv'):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data[data.columns[2:]]\n",
    "    data = data.drop(['PRE6', 'PRE14'], axis = 1)\n",
    "    label_columns = data.columns[2:12]\n",
    "    data = convert_binary(data, columns = ['Risk1Yr'])\n",
    "    data = convert_binary(data, columns = label_columns)\n",
    "    include_columns = data.columns[0:-1]\n",
    "    X, y = data[include_columns], data['Risk1Yr']\n",
    "    X, y = X.to_numpy(), y.to_numpy()\n",
    "    y[y == 0] = -1\n",
    "    return X, y, data\n",
    "\n",
    "X, y, data = load_thoracic()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When features are highly correlated, they contain redundant information, and the Random Forest may use the same feature in many of the trees, leading to overfitting. Additionally, highly correlated features can cause instability in the feature importance scores and make it difficult to interpret the results.\n",
    "\n",
    "It's always a good idea to check for highly correlated features before training a Random Forest and remove or combine them as needed. This can be done using techniques such as principal component analysis (PCA) or feature selection. By reducing the number of highly correlated features, you can simplify the model and make it more interpretable, and you may also see an improvement in performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRE4</th>\n",
       "      <th>PRE5</th>\n",
       "      <th>PRE7</th>\n",
       "      <th>PRE8</th>\n",
       "      <th>PRE9</th>\n",
       "      <th>PRE10</th>\n",
       "      <th>PRE11</th>\n",
       "      <th>PRE17</th>\n",
       "      <th>PRE19</th>\n",
       "      <th>PRE25</th>\n",
       "      <th>PRE30</th>\n",
       "      <th>PRE32</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Risk1Yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PRE4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032975</td>\n",
       "      <td>0.019786</td>\n",
       "      <td>-0.095827</td>\n",
       "      <td>0.055829</td>\n",
       "      <td>-0.052770</td>\n",
       "      <td>-0.100242</td>\n",
       "      <td>-0.115145</td>\n",
       "      <td>-0.009135</td>\n",
       "      <td>-0.035584</td>\n",
       "      <td>-0.012009</td>\n",
       "      <td>-0.060578</td>\n",
       "      <td>-0.290178</td>\n",
       "      <td>-0.046374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE5</th>\n",
       "      <td>0.032975</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.161615</td>\n",
       "      <td>0.102979</td>\n",
       "      <td>0.260073</td>\n",
       "      <td>-0.099914</td>\n",
       "      <td>-0.086103</td>\n",
       "      <td>-0.022251</td>\n",
       "      <td>-0.013617</td>\n",
       "      <td>-0.025088</td>\n",
       "      <td>-0.100853</td>\n",
       "      <td>-0.016509</td>\n",
       "      <td>-0.115900</td>\n",
       "      <td>-0.042841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE7</th>\n",
       "      <td>0.019786</td>\n",
       "      <td>0.161615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.256225</td>\n",
       "      <td>0.067529</td>\n",
       "      <td>-0.024115</td>\n",
       "      <td>-0.072455</td>\n",
       "      <td>0.022578</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>-0.034968</td>\n",
       "      <td>-0.077406</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>0.044789</td>\n",
       "      <td>0.057375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE8</th>\n",
       "      <td>-0.095827</td>\n",
       "      <td>0.102979</td>\n",
       "      <td>0.256225</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.134386</td>\n",
       "      <td>0.081772</td>\n",
       "      <td>0.060393</td>\n",
       "      <td>-0.001471</td>\n",
       "      <td>-0.026886</td>\n",
       "      <td>0.086156</td>\n",
       "      <td>-0.044942</td>\n",
       "      <td>-0.026886</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.065785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE9</th>\n",
       "      <td>0.055829</td>\n",
       "      <td>0.260073</td>\n",
       "      <td>0.067529</td>\n",
       "      <td>0.134386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.049843</td>\n",
       "      <td>-0.072455</td>\n",
       "      <td>-0.042725</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>0.097572</td>\n",
       "      <td>-0.077406</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>-0.015331</td>\n",
       "      <td>0.105530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE10</th>\n",
       "      <td>-0.052770</td>\n",
       "      <td>-0.099914</td>\n",
       "      <td>-0.024115</td>\n",
       "      <td>0.081772</td>\n",
       "      <td>0.049843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.202245</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>0.200373</td>\n",
       "      <td>-0.026401</td>\n",
       "      <td>0.149589</td>\n",
       "      <td>0.088860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE11</th>\n",
       "      <td>-0.100242</td>\n",
       "      <td>-0.086103</td>\n",
       "      <td>-0.072455</td>\n",
       "      <td>0.060393</td>\n",
       "      <td>-0.072455</td>\n",
       "      <td>0.202245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.069522</td>\n",
       "      <td>0.058695</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.118527</td>\n",
       "      <td>-0.029161</td>\n",
       "      <td>0.208003</td>\n",
       "      <td>0.086467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE17</th>\n",
       "      <td>-0.115145</td>\n",
       "      <td>-0.022251</td>\n",
       "      <td>0.022578</td>\n",
       "      <td>-0.001471</td>\n",
       "      <td>-0.042725</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.069522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>-0.036906</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>0.085081</td>\n",
       "      <td>0.108974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE19</th>\n",
       "      <td>-0.009135</td>\n",
       "      <td>-0.013617</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>-0.026886</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>0.044101</td>\n",
       "      <td>0.058695</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008602</td>\n",
       "      <td>0.030496</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>-0.030320</td>\n",
       "      <td>-0.027347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE25</th>\n",
       "      <td>-0.035584</td>\n",
       "      <td>-0.025088</td>\n",
       "      <td>-0.034968</td>\n",
       "      <td>0.086156</td>\n",
       "      <td>0.097572</td>\n",
       "      <td>0.017815</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.025328</td>\n",
       "      <td>-0.008602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.061386</td>\n",
       "      <td>-0.008602</td>\n",
       "      <td>0.058112</td>\n",
       "      <td>0.037354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE30</th>\n",
       "      <td>-0.012009</td>\n",
       "      <td>-0.100853</td>\n",
       "      <td>-0.077406</td>\n",
       "      <td>-0.044942</td>\n",
       "      <td>-0.077406</td>\n",
       "      <td>0.200373</td>\n",
       "      <td>0.118527</td>\n",
       "      <td>-0.036906</td>\n",
       "      <td>0.030496</td>\n",
       "      <td>0.061386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054820</td>\n",
       "      <td>0.068869</td>\n",
       "      <td>0.085958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRE32</th>\n",
       "      <td>-0.060578</td>\n",
       "      <td>-0.016509</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>-0.026886</td>\n",
       "      <td>-0.017372</td>\n",
       "      <td>-0.026401</td>\n",
       "      <td>-0.029161</td>\n",
       "      <td>-0.018543</td>\n",
       "      <td>-0.004274</td>\n",
       "      <td>-0.008602</td>\n",
       "      <td>-0.054820</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.019046</td>\n",
       "      <td>-0.027347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.290178</td>\n",
       "      <td>-0.115900</td>\n",
       "      <td>0.044789</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>-0.015331</td>\n",
       "      <td>0.149589</td>\n",
       "      <td>0.208003</td>\n",
       "      <td>0.085081</td>\n",
       "      <td>-0.030320</td>\n",
       "      <td>0.058112</td>\n",
       "      <td>0.068869</td>\n",
       "      <td>-0.019046</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Risk1Yr</th>\n",
       "      <td>-0.046374</td>\n",
       "      <td>-0.042841</td>\n",
       "      <td>0.057375</td>\n",
       "      <td>0.065785</td>\n",
       "      <td>0.105530</td>\n",
       "      <td>0.088860</td>\n",
       "      <td>0.086467</td>\n",
       "      <td>0.108974</td>\n",
       "      <td>-0.027347</td>\n",
       "      <td>0.037354</td>\n",
       "      <td>0.085958</td>\n",
       "      <td>-0.027347</td>\n",
       "      <td>0.038902</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRE4      PRE5      PRE7      PRE8      PRE9     PRE10     PRE11  \\\n",
       "PRE4     1.000000  0.032975  0.019786 -0.095827  0.055829 -0.052770 -0.100242   \n",
       "PRE5     0.032975  1.000000  0.161615  0.102979  0.260073 -0.099914 -0.086103   \n",
       "PRE7     0.019786  0.161615  1.000000  0.256225  0.067529 -0.024115 -0.072455   \n",
       "PRE8    -0.095827  0.102979  0.256225  1.000000  0.134386  0.081772  0.060393   \n",
       "PRE9     0.055829  0.260073  0.067529  0.134386  1.000000  0.049843 -0.072455   \n",
       "PRE10   -0.052770 -0.099914 -0.024115  0.081772  0.049843  1.000000  0.202245   \n",
       "PRE11   -0.100242 -0.086103 -0.072455  0.060393 -0.072455  0.202245  1.000000   \n",
       "PRE17   -0.115145 -0.022251  0.022578 -0.001471 -0.042725  0.016551  0.069522   \n",
       "PRE19   -0.009135 -0.013617 -0.017372 -0.026886 -0.017372  0.044101  0.058695   \n",
       "PRE25   -0.035584 -0.025088 -0.034968  0.086156  0.097572  0.017815  0.029726   \n",
       "PRE30   -0.012009 -0.100853 -0.077406 -0.044942 -0.077406  0.200373  0.118527   \n",
       "PRE32   -0.060578 -0.016509 -0.017372 -0.026886 -0.017372 -0.026401 -0.029161   \n",
       "AGE     -0.290178 -0.115900  0.044789  0.086705 -0.015331  0.149589  0.208003   \n",
       "Risk1Yr -0.046374 -0.042841  0.057375  0.065785  0.105530  0.088860  0.086467   \n",
       "\n",
       "            PRE17     PRE19     PRE25     PRE30     PRE32       AGE   Risk1Yr  \n",
       "PRE4    -0.115145 -0.009135 -0.035584 -0.012009 -0.060578 -0.290178 -0.046374  \n",
       "PRE5    -0.022251 -0.013617 -0.025088 -0.100853 -0.016509 -0.115900 -0.042841  \n",
       "PRE7     0.022578 -0.017372 -0.034968 -0.077406 -0.017372  0.044789  0.057375  \n",
       "PRE8    -0.001471 -0.026886  0.086156 -0.044942 -0.026886  0.086705  0.065785  \n",
       "PRE9    -0.042725 -0.017372  0.097572 -0.077406 -0.017372 -0.015331  0.105530  \n",
       "PRE10    0.016551  0.044101  0.017815  0.200373 -0.026401  0.149589  0.088860  \n",
       "PRE11    0.069522  0.058695  0.029726  0.118527 -0.029161  0.208003  0.086467  \n",
       "PRE17    1.000000 -0.018543  0.025328 -0.036906 -0.018543  0.085081  0.108974  \n",
       "PRE19   -0.018543  1.000000 -0.008602  0.030496 -0.004274 -0.030320 -0.027347  \n",
       "PRE25    0.025328 -0.008602  1.000000  0.061386 -0.008602  0.058112  0.037354  \n",
       "PRE30   -0.036906  0.030496  0.061386  1.000000 -0.054820  0.068869  0.085958  \n",
       "PRE32   -0.018543 -0.004274 -0.008602 -0.054820  1.000000 -0.019046 -0.027347  \n",
       "AGE      0.085081 -0.030320  0.058112  0.068869 -0.019046  1.000000  0.038902  \n",
       "Risk1Yr  0.108974 -0.027347  0.037354  0.085958 -0.027347  0.038902  1.000000  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(415)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# x = np.arange(2)\n",
    "# plt.bar(x, height = [len(y[y == 1]), len(y[y == -1])])\n",
    "# plt.xticks(x, ['Cervical Cancer', 'No Cervical Cancer'])\n",
    "# plt.ylabel('Number of Respondents')\n",
    "# plt.title('Imbalanced dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75  0]\n",
      " [19  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      1.00      0.89        75\n",
      "           1       0.00      0.00      0.00        19\n",
      "\n",
      "    accuracy                           0.80        94\n",
      "   macro avg       0.40      0.50      0.44        94\n",
      "weighted avg       0.64      0.80      0.71        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(sampling_strategy = 'minority', random_state = 42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  9]\n",
      " [16  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.88      0.84        75\n",
      "           1       0.25      0.16      0.19        19\n",
      "\n",
      "    accuracy                           0.73        94\n",
      "   macro avg       0.53      0.52      0.52        94\n",
      "weighted avg       0.69      0.73      0.71        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 1000, random_state = 4, oob_score = True, max_features = 15)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 4, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "                'n_estimators': [10, 50, 100], \n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': np.arange(1, 10),\n",
    "                'min_samples_split': np.arange(1, 5)\n",
    "              }\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "grid = GridSearchCV(model, param_grid, refit = True)\n",
    "grid.fit(X_resampled, y_resampled)\n",
    "\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55 20]\n",
      " [14  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.73      0.76        75\n",
      "           1       0.20      0.26      0.23        19\n",
      "\n",
      "    accuracy                           0.64        94\n",
      "   macro avg       0.50      0.50      0.50        94\n",
      "weighted avg       0.68      0.64      0.66        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(criterion = 'gini', n_estimators = 100, max_depth = 9, min_samples_split = 4)\n",
    "model.fit(X_resampled, y_resampled)\n",
    "yhat = model.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_split': 4, 'max_depth': 8, 'criterion': 'entropy'}\n",
      "[[57 18]\n",
      " [15  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.79      0.76      0.78        75\n",
      "           1       0.18      0.21      0.20        19\n",
      "\n",
      "    accuracy                           0.65        94\n",
      "   macro avg       0.49      0.49      0.49        94\n",
      "weighted avg       0.67      0.65      0.66        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "                'n_estimators': [10, 50, 100], \n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': np.arange(1, 10),\n",
    "                'min_samples_split': np.arange(1, 5)\n",
    "              }\n",
    "rsearch = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                           param_distributions = param_grid, \n",
    "                           cv = 5, n_iter = 10)\n",
    "\n",
    "rsearch.fit(X_resampled, y_resampled)\n",
    "print(rsearch.best_params_)\n",
    "\n",
    "yhat = grid.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "print(classification_report(y_test, yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, data = load_thoracic()\n",
    "\n",
    "def split_data(X, y, pca_included = False, smote_included = False):\n",
    "    if pca_included is True:\n",
    "        pca = PCA(n_components = 10)\n",
    "        X = pca.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "    if smote_included is True:\n",
    "        smote = SMOTE(sampling_strategy = 'minority', k_neighbors = 5, random_state = 42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "    else:\n",
    "        X_resampled, y_resampled = X_train, y_train \n",
    "    return X_resampled, y_resampled, X_test, y_test\n",
    "\n",
    "X_resampled, y_resampled, X_test, y_test = split_data(X, y, pca_included = True, smote_included = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 10, 'min_samples_split': 3, 'max_depth': 12, 'criterion': 'entropy'}\n",
      "[[65 10]\n",
      " [16  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.80      0.87      0.83        75\n",
      "           1       0.23      0.16      0.19        19\n",
      "\n",
      "    accuracy                           0.72        94\n",
      "   macro avg       0.52      0.51      0.51        94\n",
      "weighted avg       0.69      0.72      0.70        94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = { \n",
    "                'n_estimators': [10, 2000], \n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': np.arange(1, 20),\n",
    "                'min_samples_split': np.arange(1, 5)\n",
    "              }\n",
    "rsearch = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                           param_distributions = param_grid, \n",
    "                           cv = 10, n_iter = 10)\n",
    "\n",
    "rsearch.fit(X_resampled, y_resampled)\n",
    "print(rsearch.best_params_)\n",
    "\n",
    "yhat = rsearch.predict(X_test)\n",
    "print(confusion_matrix(y_test, yhat))\n",
    "print(classification_report(y_test, yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6a2dc670f3436433c0efae6fb324965c1072d8aef0b90287abce79ee9328779"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
