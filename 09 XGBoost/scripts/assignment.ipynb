{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.datasets import load_breast_cancer, load_diabetes, load_wine\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: (15718, 46)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/Breast_Cancer.csv')\n",
    "print(f'Original dataset: {data.shape}')\n",
    "\n",
    "def check_binary(df):\n",
    "    return [column for column in df.columns if df[column].isin(['Yes','No']).any()]\n",
    "\n",
    "def check_pseudobi(df):\n",
    "    return [column for column in df.columns if df[column].isin(np.arange(0.0, 5.0)).any()]\n",
    "\n",
    "def check_marital(df):\n",
    "    return [column for column in df.columns if df[column].isin(np.unique(data['marital'])).any()]\n",
    "\n",
    "def getcolumns_rate(dataframe, rate = 0.25): \n",
    "  less_than_50pct_nonnull = (dataframe.isnull().sum() / dataframe.shape[0]) < rate\n",
    "  return dataframe.columns[less_than_50pct_nonnull]\n",
    "\n",
    "def get_objectColumns(dataframe, type = 'object'):\n",
    "    return list(dataframe.select_dtypes(include = type).columns)\n",
    "\n",
    "def variance_inflation(df):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['VIF'] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "    vif['Features'] = data.columns\n",
    "    vif.sort_values(by = 'VIF', ascending = False)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n",
    "\n",
    "def report_best_scores(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate], results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "remove_columns = getcolumns_rate(data)\n",
    "data = data[remove_columns]\n",
    "data = data.dropna()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "data['bdate'] = data['bdate'].str[-4:]\n",
    "data['age']   = 2566 - data['bdate'].astype('int')\n",
    "data = data.drop('bdate', axis = 1)\n",
    "\n",
    "encode_columns = get_objectColumns(data)\n",
    "for column in encode_columns:\n",
    "    data[column] = encoder.fit_transform(data[column])\n",
    "\n",
    "data['noova'] = data['noova'].replace([9.0], [3.0], inplace = False)\n",
    "encode_columns = ['nobreast', 'nosecon', 'noova', 'inj', 'noparity']\n",
    "for column in encode_columns:\n",
    "    data[column] = encoder.fit_transform(data[column])\n",
    "\n",
    "X = data.drop('diag_cancer', axis = 1).to_numpy()\n",
    "y = data['diag_cancer'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Gradient Boosting Classifier=================\n",
      "0.9947072444591465\n",
      "[[  18   10]\n",
      " [   6 2989]]\n",
      "=============XGBoost Classifier===============\n",
      "0.9943764472378432\n",
      "[[  15   13]\n",
      " [   4 2991]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print('==============Gradient Boosting Classifier=================')\n",
    "clf = GradientBoostingClassifier(n_estimators = 100, learning_rate = 1.0, max_depth = 1, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))\n",
    "y_pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print('=============XGBoost Classifier===============')\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100,eta=0.3, gamma=0.5, random_state=0)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(xgb_model.score(X_test, y_test))\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.99897\tvalidation_0-error:0.00238\tvalidation_0-error@0.6:0.00450\n",
      "[1]\tvalidation_0-auc:0.99916\tvalidation_0-error:0.00265\tvalidation_0-error@0.6:0.00371\n",
      "[2]\tvalidation_0-auc:0.99908\tvalidation_0-error:0.00265\tvalidation_0-error@0.6:0.00265\n",
      "[3]\tvalidation_0-auc:0.99901\tvalidation_0-error:0.00291\tvalidation_0-error@0.6:0.00238\n",
      "[4]\tvalidation_0-auc:0.99906\tvalidation_0-error:0.00291\tvalidation_0-error@0.6:0.00291\n",
      "[5]\tvalidation_0-auc:0.99902\tvalidation_0-error:0.00291\tvalidation_0-error@0.6:0.00291\n",
      "[6]\tvalidation_0-auc:0.99897\tvalidation_0-error:0.00291\tvalidation_0-error@0.6:0.00291\n",
      "[7]\tvalidation_0-auc:0.99903\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00265\n",
      "[8]\tvalidation_0-auc:0.99905\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00291\n",
      "[9]\tvalidation_0-auc:0.99910\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00318\n",
      "[10]\tvalidation_0-auc:0.99912\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00291\n",
      "[11]\tvalidation_0-auc:0.99912\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00344\n",
      "[12]\tvalidation_0-auc:0.99905\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00318\n",
      "[13]\tvalidation_0-auc:0.99899\tvalidation_0-error:0.00291\tvalidation_0-error@0.6:0.00344\n",
      "[14]\tvalidation_0-auc:0.99895\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00344\n",
      "[15]\tvalidation_0-auc:0.99897\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00318\n",
      "[16]\tvalidation_0-auc:0.99895\tvalidation_0-error:0.00344\tvalidation_0-error@0.6:0.00318\n",
      "[17]\tvalidation_0-auc:0.99884\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00344\n",
      "[18]\tvalidation_0-auc:0.99877\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00344\n",
      "[19]\tvalidation_0-auc:0.99880\tvalidation_0-error:0.00318\tvalidation_0-error@0.6:0.00344\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", n_estimators=20, random_state=42, eval_metric=[\"auc\", \"error\", \"error@0.6\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "xgb_model.fit(X_train, y_train, eval_set=[(X_test, y_test)])\n",
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  23    3]\n",
      " [   7 3745]]\n"
     ]
    }
   ],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42, eval_metric=\"auc\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "xgb_model.fit(X_train, y_train, early_stopping_rounds=10, eval_set=[(X_test, y_test)], verbose=False)\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6a2dc670f3436433c0efae6fb324965c1072d8aef0b90287abce79ee9328779"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
