{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Gradient Boost Tree by showing step-by-step calculation and setting $M = 1$, $\\alpha = 0.3$ and <code>max_depth = 3</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import auc, accuracy_score, mean_squared_error\n",
    "from sklearn.impute  import KNNImputer\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from time import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: \t(15718, 46)\n",
      "Preprocessed dataset: \t(15718, 36)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/Breast_Cancer.csv')\n",
    "print(f'Original dataset: \\t{data.shape}')\n",
    "\n",
    "def check_binary(df):\n",
    "    return [column for column in df.columns if df[column].isin(['Yes','No']).any()]\n",
    "\n",
    "def check_pseudobi(df):\n",
    "    return [column for column in df.columns if df[column].isin(np.arange(0.0, 5.0)).any()]\n",
    "\n",
    "def check_marital(df):\n",
    "    return [column for column in df.columns if df[column].isin(np.unique(data['marital'])).any()]\n",
    "\n",
    "def getcolumns_rate(dataframe, rate = 0.10): \n",
    "  less_than_50pct_nonnull = (dataframe.isnull().sum() / dataframe.shape[0]) < rate\n",
    "  return dataframe.columns[less_than_50pct_nonnull]\n",
    "\n",
    "def get_objectColumns(dataframe, type = 'object'):\n",
    "    return list(dataframe.select_dtypes(include = type).columns)\n",
    "\n",
    "def variance_inflation(df):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['VIF'] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "    vif['Features'] = data.columns\n",
    "    vif.sort_values(by = 'VIF', ascending = False)\n",
    "\n",
    "def get_columnsnull(df):\n",
    "    null_columns = df.columns[df.isnull().any()]\n",
    "    return null_columns.tolist()\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n",
    "\n",
    "def impute_knn(df, column_name, n_neighbors = 5):\n",
    "    df_imputed = df.copy()\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    imputer.fit(df_imputed[[column_name]])\n",
    "    df_imputed[column_name] = imputer.transform(df_imputed[[column_name]])\n",
    "    return df_imputed\n",
    "\n",
    "def impute_average(df, columns, impute_type = 'median'):\n",
    "    df_imputed = df.copy()\n",
    "    for col in columns:\n",
    "        if impute_type == 'mean':\n",
    "            impute_val = df_imputed[col].mean()\n",
    "        elif impute_type == 'median':\n",
    "            impute_val = df_imputed[col].median()\n",
    "        else:\n",
    "            raise ValueError('Invalid imputation type')\n",
    "        df_imputed[col].fillna(impute_val, inplace=True)\n",
    "    return df_imputed\n",
    "\n",
    "def report_best_scores(results, n_top = 3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate], results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "remove_columns = getcolumns_rate(data)\n",
    "data = data[remove_columns]\n",
    "\n",
    "data['bdate'] = data['bdate'].str[-4:]\n",
    "data['age']   = 2565 - data['bdate'].astype('int')\n",
    "data = data.drop('bdate', axis = 1)\n",
    "\n",
    "encode_columns = get_objectColumns(data)\n",
    "for column in encode_columns:\n",
    "    data[column] = LabelEncoder().fit_transform(data[column])\n",
    "\n",
    "data['noova'] = data['noova'].replace([9.0], [3.0], inplace = False)\n",
    "encode_columns = ['nobreast', 'nosecon', 'noova', 'inj', 'noparity']\n",
    "for column in encode_columns:\n",
    "    data[column] = LabelEncoder().fit_transform(data[column])\n",
    "\n",
    "data = impute_knn(data, 'agemen')\n",
    "data = impute_knn(data, 'dur_brefed')\n",
    "data = impute_average(data, ['weight'], 'mean')\n",
    "data = impute_average(data, ['height'], 'mean')\n",
    "\n",
    "print(f'Preprocessed dataset: \\t{data.shape}')\n",
    "X = data.drop('diag_cancer', axis = 1).to_numpy()\n",
    "y = data['diag_cancer'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "smote = SMOTE(sampling_strategy = 'minority', k_neighbors = 10, random_state = 42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model):\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    class_names = ['Cancer', 'No Cancer']\n",
    "    \n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(\"Accuracy Score: \", np.round(accuracy_score(y_test, y_pred), 3))\n",
    "    print('Confusion Matrix : \\n', confusion)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names = class_names))\n",
    "    print(f\"\\t Fit and predict time: {np.round(time() - start, 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Accuracy Score:  0.984\n",
      "Confusion Matrix : \n",
      " [[  21    6]\n",
      " [  69 4620]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.23      0.78      0.36        27\n",
      "   No Cancer       1.00      0.99      0.99      4689\n",
      "\n",
      "    accuracy                           0.98      4716\n",
      "   macro avg       0.62      0.88      0.68      4716\n",
      "weighted avg       0.99      0.98      0.99      4716\n",
      "\n",
      "\t Fit and predict time: 0.874 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'ccp_alpha'   : np.arange(0.001, 0.1, 0.01),\n",
    "              'max_depth'   : np.arange(1, 5),\n",
    "              'criterion'   : ['gini', 'entropy']}\n",
    "\n",
    "tree_class = DecisionTreeClassifier(max_depth = 5, random_state = 1024)\n",
    "grid_search = GridSearchCV(estimator = tree_class, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 5, \n",
    "                           verbose = True,\n",
    "                           scoring = 'accuracy')\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "adaboost_dct = AdaBoostClassifier(grid_search.best_estimator_, \n",
    "                                  n_estimators  = 10, \n",
    "                                  random_state  = 42, \n",
    "                                  learning_rate = 0.001)\n",
    "model_train(adaboost_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Accuracy Score:  0.988\n",
      "Confusion Matrix : \n",
      " [[  10   17]\n",
      " [  40 4649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.20      0.37      0.26        27\n",
      "   No Cancer       1.00      0.99      0.99      4689\n",
      "\n",
      "    accuracy                           0.99      4716\n",
      "   macro avg       0.60      0.68      0.63      4716\n",
      "weighted avg       0.99      0.99      0.99      4716\n",
      "\n",
      "\t Fit and predict time: 296.97 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "              'subsample': [1.0, 0.5],\n",
    "              'max_features': np.arange(0, 10), \n",
    "              'max_depth': np.arange(0, 5)}\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators = 10, \n",
    "                                 learning_rate = 0.1, \n",
    "                                 random_state = 0)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = gradient_boosting, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 5, \n",
    "                           verbose = True,\n",
    "                           scoring = 'accuracy')\n",
    "model_train(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.994\n",
      "Confusion Matrix : \n",
      " [[  21    6]\n",
      " [  22 4667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.49      0.78      0.60        27\n",
      "   No Cancer       1.00      1.00      1.00      4689\n",
      "\n",
      "    accuracy                           0.99      4716\n",
      "   macro avg       0.74      0.89      0.80      4716\n",
      "weighted avg       1.00      0.99      0.99      4716\n",
      "\n",
      "\t Fit and predict time: 0.674 seconds\n"
     ]
    }
   ],
   "source": [
    "xgboost = xgb.XGBClassifier(n_estimators = 10, \n",
    "                            objective = 'binary:logistic',\n",
    "                            reg_lambda = 0,\n",
    "                            gamma  = 1,\n",
    "                            max_depth = 6,\n",
    "                            eta = 0.3)\n",
    "xgboost.fit(X_train, y_train)\n",
    "model_train(xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best gini of dataset: 0.5\n",
      "Sorted values: [4.8, 4.8, 5.0, 5.0, 5.2, 5.4, 5.5, 5.7, 6.3, 6.4, 6.5, 6.9]\n",
      "============Feature 0 | Value: \t5.0 ============\n",
      "Factor Left:    \t2/12\n",
      "Gini Left:      \t0.0\n",
      "Factor Right:   \t10/12\n",
      "Gini Right:     \t0.48\n",
      "\n",
      "Equation:       \t(2/12 * 0.0) + (10/12 * 0.48)\n",
      "Weighted Gini:  \t0.4\n",
      "\n",
      "============Feature 0 | Value: \t5.2 ============\n",
      "Factor Left:    \t4/12\n",
      "Gini Left:      \t0.0\n",
      "Factor Right:   \t8/12\n",
      "Gini Right:     \t0.38\n",
      "\n",
      "Equation:       \t(4/12 * 0.0) + (8/12 * 0.38)\n",
      "Weighted Gini:  \t0.25\n",
      "\n",
      "============Feature 0 | Value: \t5.4 ============\n",
      "Factor Left:    \t5/12\n",
      "Gini Left:      \t0.0\n",
      "Factor Right:   \t7/12\n",
      "Gini Right:     \t0.24\n",
      "\n",
      "Equation:       \t(5/12 * 0.0) + (7/12 * 0.24)\n",
      "Weighted Gini:  \t0.14\n",
      "\n",
      "============Feature 0 | Value: \t5.5 ============\n",
      "Factor Left:    \t6/12\n",
      "Gini Left:      \t0.0\n",
      "Factor Right:   \t6/12\n",
      "Gini Right:     \t0.0\n",
      "\n",
      "Equation:       \t(6/12 * 0.0) + (6/12 * 0.0)\n",
      "Weighted Gini:  \t0.0\n",
      "\n",
      "============Feature 0 | Value: \t5.7 ============\n",
      "Factor Left:    \t7/12\n",
      "Gini Left:      \t0.24\n",
      "Factor Right:   \t5/12\n",
      "Gini Right:     \t0.0\n",
      "\n",
      "Equation:       \t(7/12 * 0.24) + (5/12 * 0.0)\n",
      "Weighted Gini:  \t0.14\n",
      "\n",
      "============Feature 0 | Value: \t6.3 ============\n",
      "Factor Left:    \t8/12\n",
      "Gini Left:      \t0.38\n",
      "Factor Right:   \t4/12\n",
      "Gini Right:     \t0.0\n",
      "\n",
      "Equation:       \t(8/12 * 0.38) + (4/12 * 0.0)\n",
      "Weighted Gini:  \t0.25\n",
      "\n",
      "============Feature 0 | Value: \t6.4 ============\n",
      "Factor Left:    \t9/12\n",
      "Gini Left:      \t0.44\n",
      "Factor Right:   \t3/12\n",
      "Gini Right:     \t0.0\n",
      "\n",
      "Equation:       \t(9/12 * 0.44) + (3/12 * 0.0)\n",
      "Weighted Gini:  \t0.33\n",
      "\n",
      "============Feature 0 | Value: \t6.5 ============\n",
      "Factor Left:    \t10/12\n",
      "Gini Left:      \t0.48\n",
      "Factor Right:   \t2/12\n",
      "Gini Right:     \t0.0\n",
      "\n",
      "Equation:       \t(10/12 * 0.48) + (2/12 * 0.0)\n",
      "Weighted Gini:  \t0.4\n",
      "\n",
      "============Feature 0 | Value: \t6.9 ============\n",
      "Factor Left:    \t11/12\n",
      "Gini Left:      \t0.5\n",
      "Factor Right:   \t1/12\n",
      "Gini Right:     \t0.0\n",
      "\n",
      "Equation:       \t(11/12 * 0.5) + (1/12 * 0.0)\n",
      "Weighted Gini:  \t0.45\n",
      "\n",
      "Threshold: 5.45\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def find_split(X, y, n_classes):\n",
    "    n_samples, n_features = X.shape\n",
    "    if n_samples <= 1:\n",
    "        return None, None\n",
    "    \n",
    "    feature_ix, threshold = None, None\n",
    "    sample_per_class_parent = [np.sum(y == c) for c in range(n_classes)] #[2, 2]\n",
    "    best_gini = 1.0 - sum((n / n_samples) ** 2 for n in sample_per_class_parent)\n",
    "    print(f'Best gini of dataset: {best_gini}')\n",
    "\n",
    "    for feature in range(n_features):\n",
    "        sample_sorted = sorted(X[:, feature])\n",
    "        print(f'Sorted values: {sample_sorted}')\n",
    "        sort_idx = np.argsort(X[:, feature])\n",
    "        y_sorted = y[sort_idx]\n",
    "                \n",
    "        sample_per_class_left = [0] * n_classes \n",
    "        sample_per_class_right = sample_per_class_parent.copy()\n",
    "        for i in range(1, n_samples):\n",
    "            c = y_sorted[i - 1] \n",
    "\n",
    "            sample_per_class_left[c]  += 1\n",
    "            sample_per_class_right[c] -= 1\n",
    "            \n",
    "            gini_left  = 1.0 - sum((sample_per_class_left[x] / i) ** 2 for x in range(n_classes))\n",
    "            gini_right = 1.0 - sum((sample_per_class_right[x] / (n_samples - i)) ** 2 for x in range(n_classes))\n",
    "            \n",
    "            weighted_gini = ((i / n_samples) * gini_left) + ( (n_samples - i) /n_samples) * gini_right\n",
    "            if sample_sorted[i] == sample_sorted[i - 1]:\n",
    "                continue\n",
    "\n",
    "            if weighted_gini < best_gini:\n",
    "                best_gini = weighted_gini\n",
    "                feature_ix = feature\n",
    "                threshold = (sample_sorted[i] + sample_sorted[i - 1]) / 2\n",
    "            print(f'============Feature {feature} | Value: \\t{sample_sorted[i]} ============')\n",
    "            print(f'Factor Left:    \\t{i}/{n_samples}')\n",
    "            print(f'Gini Left:      \\t{np.round(gini_left, 2)}')\n",
    "            print(f'Factor Right:   \\t{n_samples - i}/{n_samples}')\n",
    "            print(f'Gini Right:     \\t{np.round(gini_right, 2)}')\n",
    "            print()\n",
    "            print(f'Equation:       \\t({i}/{n_samples} * {np.round(gini_left, 2)}) + ({n_samples - i}/{n_samples} * {np.round(gini_right, 2)})')\n",
    "            print(f'Weighted Gini:  \\t{np.round(weighted_gini, 2)}')\n",
    "            print()\n",
    "    return feature_ix, threshold\n",
    "\n",
    "data = np.array([[1, 4.8, 3.4, 1.9, 0.2, 1],\n",
    "                 [2, 5, 3, 1.6, 1.2, 1],\n",
    "                 [3, 5, 3.4, 1.6, 0.2, 1],\n",
    "                 [4, 5.2, 3.5, 1.5, 0.2, 1],\n",
    "                 [5, 4.8, 3.1, 1.6, 0.2, 1],\n",
    "                 [6, 5.4, 3.4, 1.5, 0.4, 1],\n",
    "                 [7, 6.4, 3.2, 4.7, 1.5, 0],\n",
    "                 [8, 6.9, 3.1, 4.9, 1.5, 0],\n",
    "                 [9, 5.5, 2.3, 4, 1.3, 0],\n",
    "                 [10, 6.5, 2.8, 4.6, 1.5, 0],\n",
    "                 [11, 5.7, 2.8, 4.5, 1.3, 0],\n",
    "                 [12, 6.3, 3.3, 4.7, 1.6, 0]])\n",
    "\n",
    "X = data[:, 1:2]\n",
    "y = data[:, 5].astype('int')\n",
    "\n",
    "feature_ix, threshold = find_split(X, y, 2)\n",
    "print(f'Threshold: {threshold}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6a2dc670f3436433c0efae6fb324965c1072d8aef0b90287abce79ee9328779"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
