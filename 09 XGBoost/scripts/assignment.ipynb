{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import auc, accuracy_score, mean_squared_error\n",
    "from sklearn.impute  import KNNImputer\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from time import time\n",
    "from scipy.stats import uniform, randint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset: (15718, 46)\n",
      "Preprocessed dataset: (15718, 36)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/Breast_Cancer.csv')\n",
    "print(f'Original dataset: {data.shape}')\n",
    "\n",
    "def check_binary(df):\n",
    "    return [column for column in df.columns if df[column].isin(['Yes','No']).any()]\n",
    "\n",
    "def check_pseudobi(df):\n",
    "    return [column for column in df.columns if df[column].isin(np.arange(0.0, 5.0)).any()]\n",
    "\n",
    "def check_marital(df):\n",
    "    return [column for column in df.columns if df[column].isin(np.unique(data['marital'])).any()]\n",
    "\n",
    "def getcolumns_rate(dataframe, rate = 0.10): \n",
    "  less_than_50pct_nonnull = (dataframe.isnull().sum() / dataframe.shape[0]) < rate\n",
    "  return dataframe.columns[less_than_50pct_nonnull]\n",
    "\n",
    "def get_objectColumns(dataframe, type = 'object'):\n",
    "    return list(dataframe.select_dtypes(include = type).columns)\n",
    "\n",
    "def variance_inflation(df):\n",
    "    vif = pd.DataFrame()\n",
    "    vif['VIF'] = [variance_inflation_factor(data.values, i) for i in range(data.shape[1])]\n",
    "    vif['Features'] = data.columns\n",
    "    vif.sort_values(by = 'VIF', ascending = False)\n",
    "\n",
    "def get_columnsnull(df):\n",
    "    null_columns = df.columns[df.isnull().any()]\n",
    "    return null_columns.tolist()\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores: {0}\\nMean: {1:.3f}\\nStd: {2:.3f}\".format(scores, np.mean(scores), np.std(scores)))\n",
    "\n",
    "def impute_knn(df, column_name, n_neighbors = 5):\n",
    "    df_imputed = df.copy()\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    imputer.fit(df_imputed[[column_name]])\n",
    "    df_imputed[column_name] = imputer.transform(df_imputed[[column_name]])\n",
    "    return df_imputed\n",
    "\n",
    "def impute_average(df, columns, impute_type = 'median'):\n",
    "    df_imputed = df.copy()\n",
    "    for col in columns:\n",
    "        if impute_type == 'mean':\n",
    "            impute_val = df_imputed[col].mean()\n",
    "        elif impute_type == 'median':\n",
    "            impute_val = df_imputed[col].median()\n",
    "        else:\n",
    "            raise ValueError('Invalid imputation type')\n",
    "        df_imputed[col].fillna(impute_val, inplace=True)\n",
    "    return df_imputed\n",
    "\n",
    "def report_best_scores(results, n_top = 3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                results['mean_test_score'][candidate], results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "\n",
    "remove_columns = getcolumns_rate(data)\n",
    "data = data[remove_columns]\n",
    "# data = data.dropna()\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "data['bdate'] = data['bdate'].str[-4:]\n",
    "data['age']   = 2565 - data['bdate'].astype('int')\n",
    "data = data.drop('bdate', axis = 1)\n",
    "\n",
    "encode_columns = get_objectColumns(data)\n",
    "for column in encode_columns:\n",
    "    data[column] = encoder.fit_transform(data[column])\n",
    "\n",
    "data['noova'] = data['noova'].replace([9.0], [3.0], inplace = False)\n",
    "encode_columns = ['nobreast', 'nosecon', 'noova', 'inj', 'noparity']\n",
    "for column in encode_columns:\n",
    "    data[column] = encoder.fit_transform(data[column])\n",
    "\n",
    "data = impute_knn(data, 'agemen')\n",
    "data = impute_knn(data, 'dur_brefed')\n",
    "data = impute_average(data, ['weight'], 'median')\n",
    "data = impute_average(data, ['height'], 'median')\n",
    "\n",
    "\n",
    "print(f'Preprocessed dataset: {data.shape}')\n",
    "X = data.drop('diag_cancer', axis = 1).to_numpy()\n",
    "y = data['diag_cancer'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 42)\n",
    "smote = SMOTE(sampling_strategy = 'minority', k_neighbors = 10, random_state = 42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model):\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    class_names = ['Cancer', 'No Cancer']\n",
    "    \n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(\"Accuracy Score: \", np.round(accuracy_score(y_test, y_pred), 3))\n",
    "    print('Confusion Matrix : \\n', confusion)\n",
    "    \n",
    "    print(classification_report(y_test, y_pred, target_names = class_names))\n",
    "    print(f\"\\t Fit and predict time: {np.round(time() - start, 3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 240 candidates, totalling 1200 fits\n",
      "Accuracy Score:  0.984\n",
      "Confusion Matrix : \n",
      " [[  21    6]\n",
      " [  69 4620]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.23      0.78      0.36        27\n",
      "   No Cancer       1.00      0.99      0.99      4689\n",
      "\n",
      "    accuracy                           0.98      4716\n",
      "   macro avg       0.62      0.88      0.68      4716\n",
      "weighted avg       0.99      0.98      0.99      4716\n",
      "\n",
      "\t Fit and predict time: 0.478 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'max_features': ['auto', 'sqrt', 'log2'],\n",
    "              'ccp_alpha'   : np.arange(0.001, 0.1, 0.01),\n",
    "              'max_depth'   : np.arange(1, 5),\n",
    "              'criterion'   : ['gini', 'entropy']}\n",
    "\n",
    "tree_class = DecisionTreeClassifier(max_depth = 5, random_state = 1024)\n",
    "grid_search = GridSearchCV(estimator = tree_class, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 5, \n",
    "                           verbose = True,\n",
    "                           scoring = 'accuracy')\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "\n",
    "adaboost_dct = AdaBoostClassifier(grid_search.best_estimator_, \n",
    "                                  n_estimators  = 10, \n",
    "                                  random_state  = 42, \n",
    "                                  learning_rate = 0.001)\n",
    "model_train(adaboost_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Accuracy Score:  0.988\n",
      "Confusion Matrix : \n",
      " [[  10   17]\n",
      " [  40 4649]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.20      0.37      0.26        27\n",
      "   No Cancer       1.00      0.99      0.99      4689\n",
      "\n",
      "    accuracy                           0.99      4716\n",
      "   macro avg       0.60      0.68      0.63      4716\n",
      "weighted avg       0.99      0.99      0.99      4716\n",
      "\n",
      "\t Fit and predict time: 257.308 seconds\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n",
    "              'subsample': [1.0, 0.5],\n",
    "              'max_features': np.arange(0, 10), \n",
    "              'max_depth': np.arange(0, 5)}\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators = 10, \n",
    "                                 learning_rate = 0.1, \n",
    "                                 random_state = 0)\n",
    "\n",
    "grid_search = GridSearchCV(estimator = gradient_boosting, \n",
    "                           param_grid = param_grid, \n",
    "                           cv = 5, \n",
    "                           verbose = True,\n",
    "                           scoring = 'accuracy')\n",
    "model_train(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score:  0.994\n",
      "Confusion Matrix : \n",
      " [[  21    6]\n",
      " [  22 4667]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Cancer       0.49      0.78      0.60        27\n",
      "   No Cancer       1.00      1.00      1.00      4689\n",
      "\n",
      "    accuracy                           0.99      4716\n",
      "   macro avg       0.74      0.89      0.80      4716\n",
      "weighted avg       1.00      0.99      0.99      4716\n",
      "\n",
      "\t Fit and predict time: 0.611 seconds\n"
     ]
    }
   ],
   "source": [
    "xgboost = xgb.XGBClassifier(n_estimators = 10, \n",
    "                            objective = 'binary:logistic',\n",
    "                            reg_lambda = 0,\n",
    "                            gamma  = 1,\n",
    "                            max_depth = 6,\n",
    "                            eta = 0.3)\n",
    "xgboost.fit(X_train, y_train)\n",
    "model_train(xgboost)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6a2dc670f3436433c0efae6fb324965c1072d8aef0b90287abce79ee9328779"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
